{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle = True, random_state = 1, remove = ('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased, disagree, st...\n",
       "1    [yeah, expect, people, read, actually, accept,...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4    [well, change, scoring, playoff, pool, unfortu...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faith\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64281"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.026*\"simms\" + 0.013*\"atlanta\" + 0.010*\"decenso\" + 0.009*\"dont\"')\n",
      "(1, '0.015*\"encryption\" + 0.014*\"chip\" + 0.013*\"government\" + 0.012*\"keys\"')\n",
      "(2, '0.023*\"science\" + 0.013*\"theory\" + 0.013*\"objective\" + 0.010*\"morality\"')\n",
      "(3, '0.023*\"myers\" + 0.020*\"ball\" + 0.016*\"cheers\" + 0.013*\"kent\"')\n",
      "(4, '0.021*\"game\" + 0.018*\"year\" + 0.018*\"team\" + 0.013*\"games\"')\n",
      "(5, '0.036*\"window\" + 0.020*\"motif\" + 0.017*\"widget\" + 0.017*\"server\"')\n",
      "(6, '0.014*\"power\" + 0.014*\"sale\" + 0.011*\"price\" + 0.011*\"offer\"')\n",
      "(7, '0.057*\"drive\" + 0.035*\"scsi\" + 0.034*\"disk\" + 0.020*\"hard\"')\n",
      "(8, '0.013*\"would\" + 0.012*\"like\" + 0.011*\"know\" + 0.011*\"windows\"')\n",
      "(9, '0.014*\"dept\" + 0.014*\"braves\" + 0.013*\"navy\" + 0.008*\"music\"')\n",
      "(10, '0.014*\"university\" + 0.010*\"april\" + 0.009*\"information\" + 0.008*\"national\"')\n",
      "(11, '0.016*\"health\" + 0.013*\"medical\" + 0.009*\"disease\" + 0.009*\"pain\"')\n",
      "(12, '0.024*\"file\" + 0.014*\"program\" + 0.012*\"available\" + 0.010*\"output\"')\n",
      "(13, '0.022*\"space\" + 0.008*\"nasa\" + 0.006*\"bike\" + 0.005*\"engine\"')\n",
      "(14, '0.026*\"char\" + 0.018*\"remark\" + 0.011*\"winners\" + 0.008*\"usage\"')\n",
      "(15, '0.015*\"would\" + 0.010*\"think\" + 0.010*\"people\" + 0.009*\"like\"')\n",
      "(16, '0.011*\"people\" + 0.008*\"said\" + 0.006*\"would\" + 0.004*\"israel\"')\n",
      "(17, '0.019*\"germany\" + 0.019*\"german\" + 0.012*\"nazi\" + 0.011*\"nazis\"')\n",
      "(18, '0.017*\"period\" + 0.011*\"pittsburgh\" + 0.011*\"play\" + 0.010*\"chicago\"')\n",
      "(19, '0.012*\"armenian\" + 0.011*\"turkish\" + 0.011*\"government\" + 0.009*\"armenians\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word = dictionary, passes = 15)\n",
    "topics = ldamodel.print_topics(num_words = 4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.026*\"simms\" + 0.013*\"atlanta\" + 0.010*\"decenso\" + 0.009*\"dont\" + 0.008*\"kidney\" + 0.008*\"dram\" + 0.007*\"coprocessor\" + 0.006*\"outs\" + 0.006*\"hang\" + 0.006*\"simm\"'), (1, '0.015*\"encryption\" + 0.014*\"chip\" + 0.013*\"government\" + 0.012*\"keys\" + 0.012*\"security\" + 0.012*\"clipper\" + 0.010*\"public\" + 0.010*\"system\" + 0.010*\"privacy\" + 0.007*\"technology\"'), (2, '0.023*\"science\" + 0.013*\"theory\" + 0.013*\"objective\" + 0.010*\"morality\" + 0.010*\"picture\" + 0.009*\"scientific\" + 0.009*\"values\" + 0.008*\"system\" + 0.008*\"books\" + 0.007*\"moral\"'), (3, '0.023*\"myers\" + 0.020*\"ball\" + 0.016*\"cheers\" + 0.013*\"kent\" + 0.012*\"radar\" + 0.011*\"detector\" + 0.010*\"cross\" + 0.007*\"easter\" + 0.006*\"detectors\" + 0.006*\"idle\"'), (4, '0.021*\"game\" + 0.018*\"year\" + 0.018*\"team\" + 0.013*\"games\" + 0.011*\"season\" + 0.011*\"last\" + 0.009*\"players\" + 0.008*\"good\" + 0.008*\"first\" + 0.008*\"play\"'), (5, '0.036*\"window\" + 0.020*\"motif\" + 0.017*\"widget\" + 0.017*\"server\" + 0.016*\"display\" + 0.012*\"application\" + 0.009*\"xterm\" + 0.008*\"contrib\" + 0.008*\"using\" + 0.008*\"font\"'), (6, '0.014*\"power\" + 0.014*\"sale\" + 0.011*\"price\" + 0.011*\"offer\" + 0.010*\"shipping\" + 0.009*\"condition\" + 0.009*\"cable\" + 0.008*\"wire\" + 0.008*\"used\" + 0.008*\"ground\"'), (7, '0.057*\"drive\" + 0.035*\"scsi\" + 0.034*\"disk\" + 0.020*\"hard\" + 0.018*\"drives\" + 0.016*\"controller\" + 0.014*\"floppy\" + 0.011*\"system\" + 0.010*\"tape\" + 0.010*\"bios\"'), (8, '0.013*\"would\" + 0.012*\"like\" + 0.011*\"know\" + 0.011*\"windows\" + 0.011*\"thanks\" + 0.010*\"anyone\" + 0.009*\"please\" + 0.008*\"need\" + 0.008*\"also\" + 0.007*\"problem\"'), (9, '0.014*\"dept\" + 0.014*\"braves\" + 0.013*\"navy\" + 0.008*\"music\" + 0.007*\"april\" + 0.007*\"laser\" + 0.007*\"ieee\" + 0.007*\"switzerland\" + 0.006*\"naval\" + 0.006*\"giants\"'), (10, '0.014*\"university\" + 0.010*\"april\" + 0.009*\"information\" + 0.008*\"national\" + 0.008*\"news\" + 0.007*\"center\" + 0.007*\"internet\" + 0.007*\"research\" + 0.006*\"washington\" + 0.006*\"service\"'), (11, '0.016*\"health\" + 0.013*\"medical\" + 0.009*\"disease\" + 0.009*\"pain\" + 0.008*\"food\" + 0.007*\"patients\" + 0.007*\"among\" + 0.007*\"doctor\" + 0.007*\"study\" + 0.007*\"drug\"'), (12, '0.024*\"file\" + 0.014*\"program\" + 0.012*\"available\" + 0.010*\"output\" + 0.009*\"files\" + 0.009*\"entry\" + 0.008*\"data\" + 0.008*\"information\" + 0.008*\"image\" + 0.008*\"version\"'), (13, '0.022*\"space\" + 0.008*\"nasa\" + 0.006*\"bike\" + 0.005*\"engine\" + 0.005*\"high\" + 0.005*\"also\" + 0.005*\"launch\" + 0.005*\"cars\" + 0.004*\"cost\" + 0.004*\"system\"'), (14, '0.026*\"char\" + 0.018*\"remark\" + 0.011*\"winners\" + 0.008*\"usage\" + 0.007*\"remarks\" + 0.007*\"symbol\" + 0.006*\"offense\" + 0.006*\"doug\" + 0.006*\"polygon\" + 0.005*\"pipe\"'), (15, '0.015*\"would\" + 0.010*\"think\" + 0.010*\"people\" + 0.009*\"like\" + 0.008*\"know\" + 0.007*\"even\" + 0.006*\"good\" + 0.006*\"well\" + 0.005*\"time\" + 0.005*\"could\"'), (16, '0.011*\"people\" + 0.008*\"said\" + 0.006*\"would\" + 0.004*\"israel\" + 0.004*\"jews\" + 0.004*\"time\" + 0.004*\"years\" + 0.004*\"president\" + 0.004*\"first\" + 0.004*\"know\"'), (17, '0.019*\"germany\" + 0.019*\"german\" + 0.012*\"nazi\" + 0.011*\"nazis\" + 0.010*\"homosexual\" + 0.010*\"pitcher\" + 0.010*\"homosexuality\" + 0.009*\"homosexuals\" + 0.008*\"france\" + 0.008*\"cure\"'), (18, '0.017*\"period\" + 0.011*\"pittsburgh\" + 0.011*\"play\" + 0.010*\"chicago\" + 0.009*\"detroit\" + 0.009*\"power\" + 0.009*\"boston\" + 0.008*\"hockey\" + 0.008*\"philadelphia\" + 0.008*\"montreal\"'), (19, '0.012*\"armenian\" + 0.011*\"turkish\" + 0.011*\"government\" + 0.009*\"armenians\" + 0.008*\"guns\" + 0.008*\"state\" + 0.007*\"police\" + 0.007*\"crime\" + 0.007*\"turkey\" + 0.006*\"weapons\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
